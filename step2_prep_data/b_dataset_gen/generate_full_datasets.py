import json
from argparse import ArgumentParser
from pathlib import Path
from copy import deepcopy

import pandas as pd


JSON_INDENT=2


def get_parser():
    argparser = ArgumentParser()

    argparser.add_argument(
        '-c', "--clinical_data", default='../a_clinical_data/clinical_metrics/clinical_ml.tsv', type=Path,
        help="A `.tsv` file containing a set of clinical metrics, including a patient identifier (GRP); this should "
             "be generated by the prior subset `a_clinical_data`."
    )
    argparser.add_argument(
        '-m', '--mri_path', default='../../step1_process_mri/b_stack_metrics/mri_metrics/', type=Path,
        help="A path to a directory containing `.tsv` files, one per set of MRI-derived metrics generated in the "
             "previous step, `step1_process_mri/b_stack_metrics`."
    )
    argparser.add_argument(
        '-o', '--output_folder', default='./datasets', type=Path,
        help="Folder where the resulting datasets (and configurations) will be placed within."
    )
    argparser.add_argument(
        '-t', '--template_folder', default='./config_templates', type=Path,
        help="Folder containing the MOOP configuration templates, used to generate the full configuration files for "
             "MOOP analysis."
    )


    return argparser


def clean_grps(df):
    new_df = df.copy()
    new_df['GRP'] = [int(x.split('cMRI')[-1]) for x in df['GRP']]
    return new_df


def recursive_dict_update(d1: dict, d2: dict):
    for k, new_v in d2.items():
        old_v = d1.get(k, None)
        # Lists should be extended, not replaced
        if isinstance(old_v, list):
            old_v.extend(new_v)
        # Dicts should be updated recursively
        elif isinstance(old_v, dict):
            recursive_dict_update(old_v, new_v)
        # Otherwise, replace (or create) the value in the old dictionary
        else:
            d1[k] = new_v

    # Return the result
    return d1


def generate_datasets_and_configs(
        label: str, df: pd.DataFrame, output_folder: Path, json_template: Path, template_folder: Path):
    # Generate the output folder, if it doesn't already exist
    if not output_folder.exists():
        output_folder.mkdir(parents=True)

    # Save the clinical dataframe into this folder
    data_file = output_folder / f"{label}.tsv"
    df.to_csv(data_file, sep='\t')

    # Read the clinical config template into memory
    with open(json_template, 'r') as fp:
        data_json = json.load(fp)

    # Add the source folder to the config, to be iterated upon
    data_json["data_source"] = str(data_file.resolve())

    # Generate a clinical configs folder, if it doesn't already exist
    config_folder = output_folder / "configs"
    if not config_folder.exists():
        config_folder.mkdir(parents=True)

    # Create a "module-free" config first
    file_label = f"{label}_noprep"
    data_json["label"] = file_label
    with open(config_folder / f"{file_label}.json", 'w') as fp:
        json.dump(data_json, fp, indent=JSON_INDENT)

    # Generate unique configurations for each template module (and combination therein)
    module_folder = template_folder / "modules"
    module_files = list(module_folder.glob('*.json'))

    for m in module_files:
        # Copy the clinical JSON contents to avoid stacking additions
        new_json = deepcopy(data_json)
        # Get the new label based on the module filename
        new_label = f"{label}_" + m.name.split('.')[0]
        new_json["label"] = new_label

        # Load the module's contents into memory
        with open(m, 'r') as fp:
            module_json = json.load(fp)

        # Insert the contents of the module into our config
        new_json = recursive_dict_update(new_json, module_json)

        # Save the result
        with open(config_folder / (new_label + ".json"), 'w') as fp:
            json.dump(new_json, fp, indent=JSON_INDENT)


def main(clinical_data: Path, mri_path: Path, output_folder: Path, template_folder: Path):
    # Load the clinical dataset
    clinical_df = pd.read_csv(clinical_data, sep='\t')

    clinical_df = clean_grps(clinical_df).set_index('GRP')

    # Load each imaging dataset
    mri_dfs = {
        f.name.split('.')[0]: clean_grps(pd.read_csv(f, sep='\t')).set_index('GRP')
        for f in mri_path.glob('*.tsv')
    }

    # Generate a "joined" dataset for each MRI DF, which extends it with clinical data
    full_dfs = {k: v.join(clinical_df, how='inner') for k, v in mri_dfs.items()}

    # Add the "Recovery Class" from clinical into the imaging datasets, as it's still our target metric
    rc_df = clinical_df.loc[:, ["Recovery Class"]]
    mri_dfs = {k: v.join(rc_df, how='inner') for k, v in mri_dfs.items()}

    # Split the MRI and Full dataframes into samples grouped by their MRI modality (weight, orientation, and algorithm)
    grouping_cols = ["weight", "orientation", "algorithm"]
    def _unpack_strata(df_map: dict[str, pd.DataFrame]):
        strata_df_map = {}
        for k, df in df_map.items():
            for g_idx, g_df in df.groupby(grouping_cols):
                # noinspection PyTypeChecker
                strata_label = "_".join(g_idx)
                # Drop the grouping columns, as well as the MRI run, as they are metadata at this point
                strata_df = g_df.drop(columns=[*grouping_cols, "run"])
                strata_df_map[f"{k}_{strata_label}"] = strata_df
        return strata_df_map

    mri_df_strata = _unpack_strata(mri_dfs)
    full_df_strata = _unpack_strata(full_dfs)

    # Save the clinical dataframe (and corresponding configurations)
    json_template = template_folder / "clinical.json"
    clinical_output = output_folder / "clinical"
    generate_datasets_and_configs("clinical", clinical_df, clinical_output, json_template, template_folder)

    # Save each imaging dataframe (and their corresponding configurations)
    json_template = template_folder / "imaging.json"
    img_output = output_folder / "imaging"
    for label, mri_df in mri_df_strata.items():
        generate_datasets_and_configs(f"img_{label}", mri_df, img_output, json_template, template_folder)

    # Save each full dataset (and their corresponding configurations)
    json_template = template_folder / "clinical.json"  # Imaging doesn't add anything unique currently
    full_output = output_folder / "full"
    for label, full_df in full_df_strata.items():
        generate_datasets_and_configs(f"full_{label}", full_df, full_output, json_template, template_folder)


if __name__ == '__main__':
    parser = get_parser()
    argvs = parser.parse_args().__dict__

    main(**argvs)
